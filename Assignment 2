# Load necessary libraries
library(readr)
library(reshape2)
library(ggplot2)
library(dplyr)
library(factoextra)

# Set working directory (adjust path to your system)
setwd("~/Downloads")

# Load the datasets
gei <- read.csv2("Team_2_gei_data.csv")
db <- read.csv2("Team_2_db_data.csv")

### --- PART 1: DATA CLEANING --- ###

# 1.1: Cleaning and preparing GEI and DB datasets

# Remove unnecessary columns
gei <- gei[,-1]
db <- db[,-1]

# Selecting important variables for GEI
variables <- c("DATE", "COUNTRY_NAME", "INDICATOR_NAME", "VALUE")
gei_subset <- gei[, variables]

# Reshape GEI data for each year (2017-2019)
gei_2017 <- data.frame(dcast(gei_subset[which(gei_subset$DATE == "2017"), ], COUNTRY_NAME ~ INDICATOR_NAME), YEAR = "2017")
gei_2018 <- data.frame(dcast(gei_subset[which(gei_subset$DATE == "2018"), ], COUNTRY_NAME ~ INDICATOR_NAME), YEAR = "2018")
gei_2019 <- data.frame(dcast(gei_subset[which(gei_subset$DATE == "2019"), ], COUNTRY_NAME ~ INDICATOR_NAME), YEAR = "2019")

# Merge the reshaped GEI data
gei_cleaned <- rbind(gei_2017, gei_2018, gei_2019)
colnames(gei_cleaned)[1] <- "COUNTRY"
colnames(gei_cleaned)[4] <- "GEI_score"

# Convert relevant columns to numeric
gei_cleaned[, 2:16] <- lapply(gei_cleaned[, 2:16], function(x) as.numeric(as.character(x)))

# Clean the DB data and rename columns
db_cleaned <- subset(db, select = -c(7, 8))
names(db_cleaned)[2] <- "COUNTRY"
names(db_cleaned)[5] <- "YEAR"
names(db_cleaned)[6] <- "DB_score"

# 1.1: Merge the cleaned DB and GEI datasets
db_gei_data <- merge(db_cleaned, gei_cleaned, by = c('COUNTRY', 'YEAR'))

### --- PART 2: DESCRIPTIVE ANALYSIS --- ###

# 2.1: Scatter plot of DB scores vs GEI scores
plot(db_gei_data$DB_score, db_gei_data$GEI_score,
     main = "Scatter Plot of DB Scores vs GEI Scores",
     xlab = "DB Scores",
     ylab = "GEI Scores",
     col = "blue", pch = 19)
abline(lm(GEI_score ~ DB_score, data = db_gei_data), col = "red")

# Calculate and print correlation between DB and GEI scores
correlation <- cor(db_gei_data$DB_score, db_gei_data$GEI_score) 
cat("Correlation between DB Score and GEI Score:", correlation, "\n")

# 2.2: Exploring relationships between DB Score and selected GEI variables

# 1. DB Score vs Opportunity Startup
cor_opportunity_startup <- cor(db_gei_data$DB_score, db_gei_data$Oppurtunity.startup, use = "complete.obs")
cat("Correlation between DB score and Opportunity Startup:", cor_opportunity_startup, "\n")

# Plot
plot1 <- ggplot(db_gei_data, aes(x = Oppurtunity.startup, y = DB_score)) +
  geom_point(color = 'blue') +
  geom_smooth(method = 'lm', col = 'red') +
  labs(title = 'DB Score vs Opportunity Startup', x = 'Opportunity Startup', y = 'DB Score')
print(plot1)

# 2. DB Score vs Competition
cor_competition <- cor(db_gei_data$DB_score, db_gei_data$Competition, use = "complete.obs")
cat("Correlation between DB score and Competition:", cor_competition, "\n")

# Plot
plot2 <- ggplot(db_gei_data, aes(x = Competition, y = DB_score)) +
  geom_point(color = 'blue') +
  geom_smooth(method = 'lm', col = 'red') +
  labs(title = 'DB Score vs Competition', x = 'Competition', y = 'DB Score')
print(plot2)

# 3. DB Score vs Process Innovation
cor_process_innovation <- cor(db_gei_data$DB_score, db_gei_data$Process.Innovation, use = "complete.obs")
cat("Correlation between DB score and Process Innovation:", cor_process_innovation, "\n")

# Plot
plot3 <- ggplot(db_gei_data, aes(x = Process.Innovation, y = DB_score)) +
  geom_point(color = 'blue') +
  geom_smooth(method = 'lm', col = 'red') +
  labs(title = 'DB Score vs Process Innovation', x = 'Process Innovation', y = 'DB Score')
print(plot3)

### --- PART 3: PRINCIPAL COMPONENT ANALYSIS (PCA) --- ###

# 3.1: Performing PCA on the GEI indicators
gei_indicators <- db_gei_data[, c("Competition", "Cultural.Support", "High.Growth", "Human.capital",
                                  "Internationalization", "Networking", "Oppurtunity.startup", 
                                  "Opputunity.perception", "Process.Innovation", "Product.Innovation", 
                                  "Risk.Acceptance", "Risk.Capital", "Start.up.skills", 
                                  "Technology.Absorption")]

# Perform PCA with scaling
gei_pca <- prcomp(gei_indicators, scale = TRUE)

# Summary of PCA (Variance explained by each principal component)
summary(gei_pca)

# Scree plot
fviz_eig(gei_pca, addlabels = TRUE, ylim = c(0, 70))

# Biplot to visualize principal components and contribution of each variable
fviz_pca_biplot(gei_pca, label = "var", col.var = "black") +
  ggtitle("PCA Biplot for GEI Indicators")

# View the loadings of each variable on the principal components
print(gei_pca$rotation)

### --- PART 3.2: Permutation Test --- ###

# Perform PCA using the princomp function
fitpca <- princomp(gei_indicators, cor = TRUE, scores = TRUE)

# Source the permutation test function from external R file
source("permtestPCA.R")

# Apply the permutation test to the PCA result
perm_range <- permtestPCA(gei_indicators)

# Print the result of the permutation test
print(perm_range)














######################NEW PARTS#############
#3.2


#Permutation 1-> significant



# Load necessary libraries
library(factoextra)
library(ggplot2)

# Select the numeric GEI indicators (from 'Competition' onwards and excluding 'GEI_score')
gei_indicators <- db_gei_data[, c("Competition", "Cultural.Support", "High.Growth", "Human.capital",
                                  "Internationalization", "Networking", "Oppurtunity.startup", 
                                  "Opputunity.perception", "Process.Innovation", "Product.Innovation", 
                                  "Risk.Acceptance", "Risk.Capital", "Start.up.skills", 
                                  "Technology.Absorption")]

# Perform PCA on the original data
gei_pca <- prcomp(gei_indicators, scale = TRUE)

# Calculate the variance explained by each component in the actual data
actual_var_explained <- (gei_pca$sdev^2) / sum(gei_pca$sdev^2)

# Permutation test setup
set.seed(123)  # For reproducibility
n <- nrow(gei_indicators)  # Number of rows (samples)
stat_perm <- numeric(1000)  # Store permutation results
num_permutations <- 1000    # Number of permutations

# Permutation test
for (i in 1:num_permutations) {
  set.seed(i)
  
  # Shuffle the data (permute rows)
  permuted_data <- apply(gei_indicators, 2, sample)
  
  # Run PCA on permuted data
  permuted_pca <- prcomp(permuted_data, scale = TRUE)
  
  # Calculate the variance explained by the first principal component in permuted data
  perm_var_explained <- (permuted_pca$sdev^2) / sum(permuted_pca$sdev^2)
  
  # Store the variance explained by the first component in permuted data
  stat_perm[i] <- perm_var_explained[1]  # Store PC1's variance explained
}

# Remove the first element (initialized value)
stat_perm <- stat_perm[-1]

# Plot histogram of the permutation test results
hist(stat_perm, las = 1, col = "blue",
     main = "Variance of PC1 under H_0 (Permutation Test)",
     breaks = 20,
     border = "white")

# 95% Confidence interval for the null distribution (permuted data)
quantile(stat_perm, c(0.025, 0.975))

# Observed variance explained by PC1
actual_var_explained[1]

# Compare observed value (actual PC1 variance explained) to the quantiles of the null distribution

















###New parts


#Permutation 2-> insignificant


# Load necessary libraries
library(factoextra)
library(ggplot2)

# Select the numeric GEI indicators (from 'Competition' onwards and excluding 'GEI_score')
gei_indicators <- db_gei_data[, c("Competition", "Cultural.Support", "High.Growth", "Human.capital",
                                  "Internationalization", "Networking", "Oppurtunity.startup", 
                                  "Opputunity.perception", "Process.Innovation", "Product.Innovation", 
                                  "Risk.Acceptance", "Risk.Capital", "Start.up.skills", 
                                  "Technology.Absorption")]

# Perform PCA on the original data
gei_pca <- prcomp(gei_indicators, scale = TRUE)

# Calculate the variance explained by each component in the actual data
actual_var_explained <- (gei_pca$sdev^2) / sum(gei_pca$sdev^2)

# Permutation test setup
set.seed(123)  # For reproducibility
n <- nrow(gei_indicators)  # Number of rows (samples)
stat_perm_PC2 <- numeric(1000)  # Store permutation results for PC2
num_permutations <- 1000        # Number of permutations

# Permutation test for PC2
for (i in 1:num_permutations) {
  set.seed(i)
  
  # Shuffle the data (permute rows)
  permuted_data <- apply(gei_indicators, 2, sample)
  
  # Run PCA on permuted data
  permuted_pca <- prcomp(permuted_data, scale = TRUE)
  
  # Calculate the variance explained by PC2 in permuted data
  perm_var_explained <- (permuted_pca$sdev^2) / sum(permuted_pca$sdev^2)
  
  # Store the variance explained by PC2 in permuted data
  stat_perm_PC2[i] <- perm_var_explained[2]  # Store PC2's variance explained
}

# Plot histogram of the permutation test results for PC2
hist(stat_perm_PC2, las = 1, col = "blue",
     main = "Variance of PC2 under H_0 (Permutation Test)",
     breaks = 20,
     border = "white")

# 95% Confidence interval for the null distribution (permuted data)
quantile(stat_perm_PC2, c(0.025, 0.975))

# Observed variance explained by PC2
actual_var_explained[2]

# Compare observed value (actual PC2 variance explained) to the quantiles of the null distribution




























#test*Question3.5
# Load necessary libraries
library(boot)

# --- Step 1: Calculate variance explained by the first principal component (PC1) ---

# Define a function that calculates the variance explained by PC1 for bootstrapping
boot_pca_variance <- function(data, indices) {
  # Resample the data
  boot_data <- data[indices, ]
  
  # Perform PCA on the resampled data
  pca_boot <- prcomp(boot_data, scale = TRUE)
  
  # Return the variance explained by the first principal component (PC1)
  return((pca_boot$sdev[1]^2) / sum(pca_boot$sdev^2))
}

# Perform bootstrapping with 1000 resamples for the total variance explained by PC1
set.seed(123)
boot_results_total_var <- boot(gei_indicators, statistic = boot_pca_variance, R = 1000)

# Print the bootstrap results
print(boot_results_total_var)

# Construct 95% confidence intervals for the total variance explained by PC1
total_var_ci <- boot.ci(boot_results_total_var, type = "perc")
cat("95% Confidence Interval for Total Variance Explained by PC1:\n")
print(total_var_ci)

# --- Step 2: Calculate variance explained by PC1 for each variable ---

# Define a function to calculate the variance explained by PC1 for each variable
boot_pca_variable_variance <- function(data, indices) {
  # Resample the data
  boot_data <- data[indices, ]
  
  # Perform PCA on the resampled data
  pca_boot <- prcomp(boot_data, scale = TRUE)
  
  # Get loadings for PC1 (first component)
  loadings_pc1 <- pca_boot$rotation[, 1]
  
  # Return the squared loadings (variance explained by PC1 for each variable)
  return(loadings_pc1^2)
}

# Perform bootstrapping for the variance explained by PC1 for each variable
boot_results_var_by_var <- boot(gei_indicators, statistic = boot_pca_variable_variance, R = 1000)

# Print the bootstrap results for each variable
print(boot_results_var_by_var)

# Construct 95% confidence intervals for the variance explained by PC1 for each variable
for (i in 1:ncol(gei_indicators)) {
  var_ci <- boot.ci(boot_results_var_by_var, index = i, type = "perc")
  cat(paste("95% Confidence Interval for Variance Explained by PC1 for Variable", colnames(gei_indicators)[i], ":\n"))
  print(var_ci)}
